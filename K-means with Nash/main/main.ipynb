{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<h2> 0. Global Constance & Variable</h2>\n",
    "Config global values\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "_DATASET_ADDRESS_ = './dataset/'\n",
    "_PICKLE_ADDRESS_ = './pickle/'\n",
    "\n",
    "_DELTA_ = 0.00005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기본 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# SVD 행렬축소\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# 제작 함수\n",
    "import func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 주어진 ratings 데이터 :  (100000, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#데이터 불러오기\n",
    "ratings = pd.read_csv(\"u.data.txt\", header=None, sep='\\t')\n",
    "ratings.columns = ['userid','movieid','rating','timestamp']\n",
    "ratings = ratings.drop(['timestamp'], axis=1)\n",
    "print(\"총 주어진 ratings 데이터 : \", ratings.shape)\n",
    "rating_table= pd.pivot_table(ratings, values='rating', index=['userid'], columns=['movieid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80000 row\n",
    "user_train_raw = pd.read_csv(_DATASET_ADDRESS_ + 'u1.base', sep='\\t',names=[\"userID\",\"itemID\",\"rating\",\"timestamp\"],header=None, na_filter=False)\n",
    "user_train_raw = user_train_raw[['userID','itemID','rating']]\n",
    "user_train = user_train_raw.pivot_table('rating', index = 'userID',columns = 'itemID').fillna(0)\n",
    "user_train_raw = user_train_raw.pivot_table('rating', index = 'userID',columns = 'itemID')\n",
    "\n",
    "# 20000 row\n",
    "user_test = pd.read_csv(_DATASET_ADDRESS_ + 'u1.test', sep='\\t',names=[\"userID\",\"itemID\",\"rating\",\"timestamp\"],header=None, na_filter=False)\n",
    "user_test = user_test[['userID','itemID','rating']]\n",
    "user_test = user_test.pivot_table('rating', index = 'userID',columns = 'itemID').fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>MF define</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def matrix_factorization(R, P, Q, K, steps=300, alpha=0.0002, beta=0.02):\n",
    "\n",
    "    \n",
    "\n",
    "    '''\n",
    "    R: rating matrix\n",
    "    P: |U| * K (User features matrix)\n",
    "    Q: |D| * K (Item features matrix)\n",
    "    K: latent features\n",
    "    steps: iterations\n",
    "    alpha: learning rate\n",
    "    beta: regularization parameter\n",
    "    '''\n",
    "    Q = Q.T\n",
    "\n",
    "    start = time.time()\n",
    "    for step in range(steps):\n",
    "        print('epoch: %d, time: %f'%(step, time.time()-start))\n",
    "        for i in range(len(R)):\n",
    "            for j in range(len(R[0])):\n",
    "                if R[i][j] > 0:\n",
    "                    # calculate error\n",
    "                    eij = R[i][j] - numpy.dot(P[i,:],Q[:,j])\n",
    "\n",
    "                    for k in range(K):\n",
    "                        # calculate gradient with a and beta parameter\n",
    "                        P[i][k] = P[i][k] + alpha * (2 * eij * Q[k][j] - beta * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + alpha * (2 * eij * P[i][k] - beta * Q[k][j])\n",
    "\n",
    "        eR = numpy.dot(P,Q)\n",
    "\n",
    "        e = 0\n",
    "\n",
    "        for i in range(len(R)):\n",
    "\n",
    "            for j in range(len(R[0])):\n",
    "\n",
    "                if R[i][j] > 0:\n",
    "\n",
    "                    e = e + pow(R[i][j] - numpy.dot(P[i,:],Q[:,j]), 2)\n",
    "\n",
    "                    for k in range(K):\n",
    "\n",
    "                        e = e + (beta/2) * (pow(P[i][k],2) + pow(Q[k][j],2))\n",
    "        # 0.001: local minimum\n",
    "        if e < 0.001:\n",
    "\n",
    "            break\n",
    "\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing Result...\n"
     ]
    }
   ],
   "source": [
    "# N: num of User\n",
    "try:\n",
    "    with open(_PICKLE_ADDRESS_ + 'user_train.mf.pkl', 'rb') as f: \n",
    "        user_train_mf = pickle.load(f)\n",
    "        print(\"Found existing Result...\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No existing Result, Calculating...\")\n",
    "\n",
    "    user_train_np = user_train.to_numpy()\n",
    "\n",
    "    N = len(user_train_np)\n",
    "    # M: num of Movie\n",
    "    M = len(user_train_np[0])\n",
    "\n",
    "    K = 5  #이거를 [5, 10, 15, 20, 25, 30]\n",
    "    \n",
    "    P = np.random.rand(N,K)\n",
    "    Q = np.random.rand(M,K)\n",
    "\n",
    "    #   nP, nQ = matrix_factorization(user_train_np, P, Q, K)\n",
    "    #user_train_mf = pd.DataFrame(nP@nQ.T)\n",
    "    with open(_PICKLE_ADDRESS_ + 'user_train.mf.pkl', 'wb') as f:\n",
    "        pickle.dump(user_train, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train data :</h3>\n",
    "<ol>\n",
    "    <li>user_train_raw : rating with <strong>NaN</strong></li>\n",
    "    <li>user_train     : rating filled with <strong>0</strong></li>\n",
    "    <li>user_train_mf  : rating filled by <strong>MF</strong></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((943, 1650), (943, 1650), (943, 1650))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test for loaded datas\n",
    "\n",
    "user_train_mf.shape, user_train_raw.shape, user_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "<br><br><br><br><br>\n",
    "<hr>\n",
    "<h2> 2. Group clustering with K-means</h2>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\_CSE\\Python\\Anaconda\\envs\\KDD\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from func import clustering\n",
    "\n",
    "train_data, test_data, km_center = clustering(6, user_train_mf, user_train, user_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(942, 1651)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>\n",
    "<br><br><br><br><br>\n",
    "<hr>\n",
    "<h2> 3. Group recommendation</h2>\n",
    "<ol>\n",
    "    <li> 1) AVG</li>\n",
    "    <li> 2) LM</li>\n",
    "    <li> 3) Nash</li>\n",
    "</ol>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1) AVG</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1650)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_train_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>3) Nash</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nash_train = user_train_raw\n",
    "stat = []\n",
    "for idx, item in nash_train.T.iterrows() :\n",
    "    stat.append([item.count(), item.sum()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat[1609][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_train = []\n",
    "for uidx, user in nash_train.iterrows() :\n",
    "    iidx = 0\n",
    "    tmp = []\n",
    "    for item in user :\n",
    "        userMean = stat[iidx][1] / stat[iidx][0]\n",
    "        hasRated = not math.isnan(item)\n",
    "        deltaSum = stat[iidx][1] - (item if hasRated else 0)\n",
    "        deltaCount = stat[iidx][0] - (1 if hasRated else 0)\n",
    "        tmp.append((userMean + _DELTA_) * deltaCount / (deltaSum + _DELTA_))\n",
    "        iidx += 1\n",
    "    delta_train.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 1.00029965, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.00095277, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.00095566, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_train = np.array(delta_train)\n",
    "delta_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('KDD')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18fbb93e9d945e0c2a56ec43efd4745b822f35ea7c30ab7b0d3801077f7ce619"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
